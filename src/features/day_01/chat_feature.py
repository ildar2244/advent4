"""Chat feature implementation for Day 01 with multi-LLM support."""
import logging
from typing import AsyncGenerator

from telegram import Update, InlineKeyboardButton, InlineKeyboardMarkup
from telegram.ext import ContextTypes

from src.features.base import BaseFeature
from src.llm.base import BaseLLM
from src.llm.factory import LLMFactory
from src.utils.typing import LLMResponse

logger = logging.getLogger(__name__)


class ChatFeature(BaseFeature):
    """Chat feature allowing users to chat with AI and select LLM provider."""
    
    def __init__(self, config):
        """Initialize chat feature.
        
        Args:
            config: Application configuration
        """
        self.config = config
        self.llm_providers = {}
        self._conversations = {}
        self._initialize_providers()
    
    def _initialize_providers(self):
        """Initialize LLM providers."""
        for provider_name in LLMFactory.get_available_providers():
            try:
                provider = LLMFactory.create(provider_name, self.config)
                self.llm_providers[provider_name] = provider
                logger.info(f"Initialized provider: {provider_name}")
            except Exception as e:
                logger.error(f"Failed to initialize provider {provider_name}: {e}")
    
    @property
    def command(self) -> str:
        """Return the command name."""
        return "start"
    
    @property
    def callback_pattern(self) -> str:
        """Return the callback pattern for inline buttons."""
        return "^llm_"
    
    def get_model_selection_keyboard(self) -> InlineKeyboardMarkup:
        """Get inline keyboard for model selection."""
        keyboard = []
        for provider_name, provider in self.llm_providers.items():
            keyboard.append([
                InlineKeyboardButton(
                    provider.display_name,
                    callback_data=f"llm_{provider_name}"
                )
            ])
        return InlineKeyboardMarkup(keyboard)
    
    async def handle_command(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """Handle /start command."""
        user_id = update.effective_user.id
        message = update.message
        
        if not message:
            return
        
        # Initialize user data
        if 'selected_llm' not in context.user_data:
            context.user_data['selected_llm'] = LLMFactory.get_default_provider()
        
        welcome_message = (
            "ðŸ‘‹ ÐŸÑ€Ð¸Ð²ÐµÑ‚! Ð¯ Ñ‚Ð²Ð¾Ð¹ Ð˜Ð˜-Ð°ÑÑÐ¸ÑÑ‚ÐµÐ½Ñ‚ Ñ Ð¿Ð¾Ð´Ð´ÐµÑ€Ð¶ÐºÐ¾Ð¹ Ð½ÐµÑÐºÐ¾Ð»ÑŒÐºÐ¸Ñ… Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹!\n\n"
            "Ð’Ñ‹Ð±ÐµÑ€Ð¸ Ð¼Ð¾Ð´ÐµÐ»ÑŒ Ð´Ð»Ñ Ð½Ð°Ñ‡Ð°Ð»Ð° Ð´Ð¸Ð°Ð»Ð¾Ð³Ð°:"
        )
        
        keyboard = self.get_model_selection_keyboard()
        await message.reply_text(welcome_message, reply_markup=keyboard)
        
        # Show instructions
        instructions = (
            "ðŸ“ ÐšÐ°Ðº Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÑŒ:\n"
            "1. Ð’Ñ‹Ð±ÐµÑ€Ð¸ Ð¼Ð¾Ð´ÐµÐ»ÑŒ Ð½Ð°Ð¶Ð°Ð² Ð½Ð° ÐºÐ½Ð¾Ð¿ÐºÑƒ\n"
            "2. ÐŸÑ€Ð¾ÑÑ‚Ð¾ Ð½Ð°Ð¿Ð¸ÑˆÐ¸ ÑÐ²Ð¾Ð¹ Ð²Ð¾Ð¿Ñ€Ð¾Ñ\n"
            "3. Ð‘Ð¾Ñ‚ Ð¾Ñ‚Ð²ÐµÑ‚Ð¸Ñ‚ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÑ Ð²Ñ‹Ð±Ñ€Ð°Ð½Ð½ÑƒÑŽ Ð¼Ð¾Ð´ÐµÐ»ÑŒ\n\n"
            "Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐ¹ ÐºÐ½Ð¾Ð¿ÐºÐ¸ Ð²Ñ‹ÑˆÐµ Ñ‡Ñ‚Ð¾Ð±Ñ‹ Ð¿ÐµÑ€ÐµÐºÐ»ÑŽÑ‡Ð¸Ñ‚ÑŒ Ð¼Ð¾Ð´ÐµÐ»ÑŒ Ð² Ð»ÑŽÐ±Ð¾Ð¹ Ð¼Ð¾Ð¼ÐµÐ½Ñ‚"
        )
        await message.reply_text(instructions)
    
    async def handle_callback(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """Handle callback from model selection buttons."""
        query = update.callback_query
        
        if not query:
            return
        
        await query.answer()
        
        # Extract provider name from callback_data
        provider_name = query.data.replace("llm_", "")
        
        if provider_name not in self.llm_providers:
            await query.edit_message_text(
                f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ°: Ð¼Ð¾Ð´ÐµÐ»ÑŒ '{provider_name}' Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½Ð°"
            )
            return
        
        # Save selected provider
        context.user_data['selected_llm'] = provider_name
        
        provider = self.llm_providers[provider_name]
        await query.edit_message_text(
            f"âœ… Ð’Ñ‹Ð±Ñ€Ð°Ð½Ð° Ð¼Ð¾Ð´ÐµÐ»ÑŒ: {provider.display_name}\n\n"
            "ÐÐ°Ð¿Ð¸ÑˆÐ¸ ÑÐ²Ð¾Ð¹ Ð²Ð¾Ð¿Ñ€Ð¾Ñ!"
        )
    
    async def handle_message(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """Handle regular text messages."""
        user_id = update.effective_user.id
        message = update.message
        
        if not message or not message.text:
            return
        
        # Get selected LLM provider
        provider_name = context.user_data.get('selected_llm', LLMFactory.get_default_provider())
        
        if provider_name not in self.llm_providers:
            await message.reply_text(
                "âŒ ÐžÑˆÐ¸Ð±ÐºÐ°: Ð¼Ð¾Ð´ÐµÐ»ÑŒ Ð½Ðµ Ð²Ñ‹Ð±Ñ€Ð°Ð½Ð°. Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐ¹ /start Ð´Ð»Ñ Ð²Ñ‹Ð±Ð¾Ñ€Ð° Ð¼Ð¾Ð´ÐµÐ»Ð¸."
            )
            return
        
        provider = self.llm_providers[provider_name]
        
        # Get conversation history
        conversation_history = self._conversations.get(user_id, [])
        
        try:
            # Send typing indicator
            from src.bot.handlers.base import BaseHandler
            await BaseHandler.send_typing_indicator(context, update.effective_chat.id)
            
            # Generate response
            full_response = ""
            model_name = ""
            
            async for response_chunk in provider.generate_response(message.text):
                full_response += response_chunk.content
                model_name = response_chunk.model_name
            
            # Update conversation history
            conversation_history.append({"role": "user", "content": message.text})
            conversation_history.append({"role": "assistant", "content": full_response})
            self._conversations[user_id] = conversation_history
            
            # Send response with model info
            response_message = self._format_response(full_response, model_name)
            
            # Add keyboard for quick model switch
            keyboard = self.get_model_selection_keyboard()
            await message.reply_text(response_message, reply_markup=keyboard)
            
        except Exception as e:
            logger.error(f"Error generating response: {e}", exc_info=True)
            error_message = (
                "âŒ ÐŸÑ€Ð¾Ð¸Ð·Ð¾ÑˆÐ»Ð° Ð¾ÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ð¸ Ð¾Ñ‚Ð²ÐµÑ‚Ð°.\n\n"
                "ÐŸÐ¾Ð¶Ð°Ð»ÑƒÐ¹ÑÑ‚Ð°, Ð¿Ð¾Ð¿Ñ€Ð¾Ð±ÑƒÐ¹Ñ‚Ðµ Ð¿Ð¾Ð·Ð¶Ðµ Ð¸Ð»Ð¸ Ð²Ñ‹Ð±ÐµÑ€Ð¸Ñ‚Ðµ Ð´Ñ€ÑƒÐ³ÑƒÑŽ Ð¼Ð¾Ð´ÐµÐ»ÑŒ."
            )
            await message.reply_text(error_message)
    
    @staticmethod
    def _format_response(content: str, model: str) -> str:
        """Format response with model information.
        
        Args:
            content: Response content
            model: Model name
            
        Returns:
            Formatted response
        """
        return f"{content}\n\n---\nðŸ¤– ÐœÐ¾Ð´ÐµÐ»ÑŒ: {model}"

